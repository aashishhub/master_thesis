{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815351a0",
   "metadata": {},
   "source": [
    "## Thesis Scripts:\n",
    "This notebook is prepared by Aashish while working in his thesis project at Wageningen University and Research. His thesis topic is \"Genetic variants in gene related to milk oligosaccharides content in a diverse pig population\".\n",
    "\n",
    "##### Supervisors: Henk Bovenhuis and Martijn Derks\n",
    "\n",
    "##### Date: Feb'2023 - July' 2023\n",
    "\n",
    "Data : \"vcf\" file of around more than 400 pigs (including non-sus species).\n",
    "Tools mainly used: PLINK, bcftools, vcftools, Beagle, geneHapR. He constructed haplotype network using popart.\n",
    "\n",
    "### Project methodology:\n",
    "1) Identify candidate genes from other species via detailed literature review (GWAS, Transcriptomics) and come up with a list of genes that might be responsible for oligosaccharides synthesis in pig milk.\n",
    "\n",
    "2) Do Principal component analysis to see population structure using vcf files.\n",
    "\n",
    "3) Parse vcf information, subsetting vcf based on samples and genes.\n",
    "\n",
    "4) Predict the consequence of variants (Missense, high impact variants and those variants that have been shown to effect phenotype in literature)\n",
    "\n",
    "5) Calculate the allele frequency for each variants across population and within different breeds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94068dce",
   "metadata": {},
   "source": [
    "### Downloading tools and softwares\n",
    "\n",
    "#### Tool used : Conda/Anaconda\n",
    "\n",
    "Miniconda is a free minimal installer for conda. It is a small, bootstrap version of Anaconda that includes only conda, Python, the packages they depend on, and a small number of other useful packages, including pip, zlib and a few others. Use the conda install command to install 720+ additional conda packages from the Anaconda repository.\n",
    "\n",
    "##### To download Miniconda3 into home directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32448acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "$ ./Miniconda3-latest-Linux-x86_64.sh #or $ bash Miniconda3-latest-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5067455",
   "metadata": {},
   "source": [
    "For more details on Conda, visit:\n",
    "1) https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html\n",
    "\n",
    "2) https://docs.conda.io/projects/conda/en/latest/user-guide/cheatsheet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94ae2a",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "#### Tool used : Plink and R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1323ae",
   "metadata": {},
   "source": [
    "All the codes that are given below are for the HPC annuna terminal. First, PLINK module should be loaded into the HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ module load plink/1.9-180913"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c6f4a0",
   "metadata": {},
   "source": [
    "Once, plink is loaded into the server it can be used to run plink. The below code is for generating \"eigenvec\" and \"eigenvalue\" files. The input file is compressed \"vcf file\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac734a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ plink --vcf <sample.vcf.gz> --double-id –pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4759b7",
   "metadata": {},
   "source": [
    "The above code will generate .eigenvec and .eigenval files. Next step is to plot PC1 and PC2 using R. Below is the R script to make PCA plot out of .eigenvec and .eigenval files that was generated using PLINK.\n",
    "#### Important:\n",
    "1) Modify your \"sample.eigenvec\" file by adding factors (for eg: origin, breeds) on the last column(23rd) to make PCA clustering based on factor that you want to cluster. \n",
    "2) The input file is given as argument (below in code). That means we need to run additional code with below R script and \"sample.eigenvec\" file which is modified by including factors in 23rd column of eigenvec file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bfff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is a sample.R Rscript file\n",
    "\n",
    "#!/usr/bin/env Rscript \n",
    "pdf(\"PCA_pruned.pdf\") \n",
    "args = commandArgs(trailingOnly=TRUE)\n",
    "pca <- read.table(args[1], row.names=1)\n",
    "pca\n",
    "col.rainbow <- rainbow(7)\n",
    "palette(col.rainbow)\n",
    "family <- as.factor(pca[,22])\n",
    "plot(pca$V3, pca$V4,,col=family, pch=19, cex=0.4, xlab=\"\", ylab=\"\")\n",
    "legend(\"bottomright\", col=unique(family), legend=unique(family), pch=19)\n",
    "title(main=\"PCA Cobb\", xlab=\"PC1\", ylab=\"PC2\")\n",
    "text(pca$V3, pca$V4, rownames(pca), cex=0.2)  ## to add sample names  in points of plot\n",
    "dev.off()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e11e403",
   "metadata": {},
   "source": [
    "Finally, run these codes below. \n",
    "Note: sample.R file is the file R script file with .R extension and modified.eigenvec is the eigenvec file with added column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ module load R\n",
    "\n",
    "$ Rscript <sample.R> <modified.eigenvec>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ca0d72",
   "metadata": {},
   "source": [
    "Alternatively, I also have a code to plot PCA result using R but on CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "```\n",
    "\n",
    "\n",
    "# read in result files\n",
    "```{r}\n",
    "eigenValues <- read.delim(\"plink.eigenval\", delim = \" \", col_names = F, show_col_types = FALSE)\n",
    "view(eigenValues)\n",
    "eigenValue <- read_csv(\"Without_NA.csv\")  ### This file contains column with Animal ID, PC1, PC2, Breed and Origin\n",
    "view(eigenValue)\n",
    "\n",
    "```\n",
    "\n",
    "# proportion of variance captured by each component\n",
    "```{r}\n",
    "pve <- round((eigenValues / (sum(eigenValues))*100), 2)  ### This provides the % of variation explained by each PCs\n",
    "\n",
    "```\n",
    "\n",
    "#PCA plot on above csv file\n",
    "```{r}\n",
    "eigenValue %>% \n",
    "  ggplot(aes(PC1, PC2, colour = Origin))+\n",
    "  geom_point(size = 1, show.legend = TRUE) +\n",
    "  geom_hline(yintercept = -0.0065, linetype=\"dotted\") +\n",
    "  geom_vline(xintercept = -0.00225, linetype=\"dotted\") +\n",
    "  labs(title = \"PCA\",\n",
    "       x = paste0(\"PC1 (\", round(pve[1,1],2),\" %)\"),\n",
    "       y = paste0(\"PC2 (\", round(pve[2,1],2),\" %)\"))\n",
    "theme_minimal()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908b3aa0",
   "metadata": {},
   "source": [
    "### Parsing VCF File\n",
    "#### Tool used: bcftools , ensemblvep, PyVCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#author: Aashish Gyawali\n",
    "#purpose: Script pipeline for thesis analysis\n",
    "#SBATCH --time=200\n",
    "#SBATCH -n 1\n",
    "#SBATCH -c 1\n",
    "#SBATCH --error=error_pipeline.txt\n",
    "#SBATCH --job-name=Thesis_Aashish\n",
    "#SBATCH --mem=10000\n",
    "#SBATCH --mail-user=aashish.gyawali@wur.nl\n",
    "\n",
    "#exporting the plugins to update the vcf file for the allele frequency\n",
    "\n",
    "export BCFTOOLS_PLUGINS=/home/WUR/gyawa001/miniconda3/libexec/bcftools/  # this is important to update AF in subset of VCF file that will be later created using \"bcftools/1.17\"\n",
    "\n",
    "#to subset VCF file with whole sample into file containing only asian wild samples.\n",
    "bcftools view -S asianwild_samples.txt Sscrofa11.1_Chr6.vcf.gz | bcftools +fill-tags | bgzip -c > asianwild_Chr6.vcf.gz\n",
    "\n",
    "# to index the subsetted vcf file\n",
    "bcftools index asianwild_Chr6.vcf.gz\n",
    "\n",
    "# to get the vcf for certain region of genome. Here shows the example of FUT1\n",
    "bcftools view -O v -e 'AC=0' -r 6:54034166-54081014 asianwild_Chr6.vcf.gz > asianwild_FUT1.vcf.gz\n",
    "\n",
    "echo \"Asian Wild done\"\n",
    "\n",
    "#same for rest of samples:\n",
    "bcftools view -S asiandom_samples.txt Sscrofa11.1_Chr6.vcf.gz | bcftools +fill-tags | bgzip -c > asiandom_Chr6.vcf.gz\n",
    "bcftools index asiandom_Chr6.vcf.gz\n",
    "bcftools view -O v -e 'AC=0' -r 6:54076931-54081014 asiandom_Chr6.vcf.gz > asiandom_FUT1.vcf.gz\n",
    "\n",
    "echo \"Asian Domestic done\"\n",
    "# and so on\n",
    "\n",
    "# to run vep first we need to activate conda environment\n",
    "conda activate vep\n",
    "module load vep\n",
    "\n",
    "#running vep for each of the vcf file\n",
    "#this will generate vep file and html summary file for each genes and population\n",
    "\n",
    "vep -i asianwild_FUT1.vcf.gz --offline --dir /lustre/nobackup/WUR/ABGC/gyawa001/cache --force_overwrite --species sus_scrofa --pick --vcf --sift b -o asianwild_FUT1.vep.vcf\n",
    "vep -i asiandom_FUT1.vcf.gz --offline --dir /lustre/nobackup/WUR/ABGC/gyawa001/cache --force_overwrite --species sus_scrofa --pick --vcf --sift b -o asiandom_FUT1.vep.vcf\n",
    "\n",
    "echo \"vep done\"\n",
    "\n",
    "echo \"parsing information from vep\"\n",
    "\n",
    "module load python/3.9\n",
    "\n",
    "# parse_genes_variants_WGS.py is a python code to parse information with Allele frequency per group and asianwild_FUT1.vep.vcf is a vcf file with vep done already from above code.\n",
    "\n",
    "python parse_genes_variants_WGS.py asianwild_FUT1.vep.vcf > asianwild_FUT1.txt\n",
    "python parse_genes_variants_WGS.py asiandom_FUT1.vep.vcf > asiandom_FUT1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17bbc86",
   "metadata": {},
   "source": [
    "Script for parse_genes_variants_WGS.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script to parse variants in a VCF file \n",
    "## Install vcf,intermine, and subprocess package using: \n",
    "## 1. pip install PyVCF --user\n",
    "## 2. pip install intermine --user\n",
    "## 3. pip install subprocess --user\n",
    "\n",
    "import sys\n",
    "import vcf\n",
    "from intermine.webservice import Service\n",
    "from subprocess import Popen, PIPE\n",
    "import subprocess\n",
    "import pysam\n",
    "\n",
    "def sample_dic():\n",
    "    \"\"\" Read sample breed information \"\"\"\t\n",
    "    sample_dic={}\n",
    "    species_list = open(\"/lustre/nobackup/WUR/ABGC/gyawa001/final_species_list.tsv\",\"r\") #location and file name of sample list\n",
    "    header = species_list.readline()\n",
    "    for sample in species_list:\n",
    "        sample = sample.strip().split(\"\\t\")\n",
    "        samplename, origin, race_species, line_country, pigid = sample[0],sample[1],sample[2],sample[3],sample[4]\n",
    "        sample_dic[samplename] = [origin.strip(), race_species.strip(), line_country.strip()]\n",
    "    return sample_dic\n",
    "    \n",
    "def get_vcf_information(sample_dic):\n",
    "    \"\"\" Read VCF file and parse output \"\"\"\n",
    "    vcf_reader = vcf.Reader(filename=sys.argv[1], strict_whitespace=True)\n",
    "    print(\"Chr\\tPos\\tRef\\tAlt\\tRef_Homozygotes\\tHeterozygotes\\tAlt_Homozygotes\\tMissing\\tRef_Hom_samples\\tHet_samples\\tAlt_Hom_samples\\tMissing_samples\\tBreed\\tCSQ\\tIMPACT\\tAF\\tBreed_AF\")\n",
    "    gene_go_dic={}\n",
    "    mgi_dic={}\n",
    "    \n",
    "    for record in vcf_reader:\n",
    "        if int(record.INFO['AC'][0]) < 1:\n",
    "            continue\n",
    "        breed_dic={}\n",
    "        freq_dic={}\n",
    "        breed_count={}\n",
    "        hom_ref_samples,het_samples,hom_samples,mis_samples=[],[],[],[]\n",
    "        for sample in record.get_hom_refs():\n",
    "            hom_ref_samples.append(sample.sample)\n",
    "            breed = \"-\".join(sample_dic[sample.sample][1:])\n",
    "            if breed in breed_count:\n",
    "                breed_count[breed] +=2\n",
    "            else:\n",
    "                breed_count[breed] = 2\n",
    "                \n",
    "        for sample in record.get_hets():\n",
    "            het_samples.append(sample.sample)\n",
    "            breed = \"-\".join(sample_dic[sample.sample][1:]) ## Normal\n",
    "            #breed = sample_dic[sample.sample][2] ## origin\n",
    "            if breed in breed_dic:\n",
    "                breed_dic[breed] +=1\n",
    "                freq_dic[breed] +=1\n",
    "            else:\n",
    "                breed_dic[breed] = 1\n",
    "                freq_dic[breed] =1\n",
    "            if breed in breed_count:\n",
    "                breed_count[breed] +=2\n",
    "            else:\n",
    "                breed_count[breed] = 2\n",
    "                \n",
    "        for sample in record.get_hom_alts():\n",
    "            hom_samples.append(sample.sample)\n",
    "            breed = \"-\".join(sample_dic[sample.sample][1:]) ## Normal\n",
    "            #breed = sample_dic[sample.sample][2] ## origin\n",
    "            if breed in breed_dic:\n",
    "                breed_dic[breed] +=1\n",
    "                freq_dic[breed] +=2\n",
    "            else:\n",
    "                breed_dic[breed] = 1\n",
    "                freq_dic[breed] = 2\n",
    "            if breed in breed_count:\n",
    "                breed_count[breed] +=2\n",
    "            else:\n",
    "                breed_count[breed] = 2\n",
    "                \n",
    "        for sample in record.get_unknowns():\n",
    "            mis_samples.append(sample.sample)\n",
    "        if het_samples == []:\n",
    "            het_samples = [\"-\"]\n",
    "        if hom_samples == []:\n",
    "            hom_samples = [\"-\"]\n",
    "        if mis_samples == []:\n",
    "            mis_samples = [\"-\"]\n",
    "        csq=record.INFO['CSQ'][0].split(\"|\")\n",
    "        csq_impact=csq[2]\n",
    "        sym,geneid=csq[3],csq[4]\n",
    "        \n",
    "        ## get GO annotation\n",
    "        #go, gene_go_dic = gene_ontology(geneid,gene_go_dic)\n",
    "        #go_output = geneid+\":\"+go\n",
    "        \n",
    "        ## Get phenotypes\n",
    "        #phenotypes, mgi_dic = get_homologous_phenotypes(geneid, mgi_dic)\n",
    "        #phenotypes=phenotypes.split(\"\\t\")\n",
    "        #if phenotypes==\"\":\n",
    "        #    phenotypes=[\"-\",\"-\",\"-\"]\t        \n",
    "            \n",
    "        ## get frequencies per breed\n",
    "        freq_list=[]\n",
    "        #pCADD_score = pCADD(record.CHROM,record.POS,record.ALT[0])\t\n",
    "        for breed in freq_dic:\n",
    "            freq_list.append(breed+\":\"+str(round(float(freq_dic[breed])/breed_count[breed],2)))\n",
    "        breed = \", \".join([\"=\".join([key, str(val)]) for key, val in breed_dic.items()])\t\n",
    "        outlist= [record.CHROM,record.POS,record.REF,record.ALT,record.num_hom_ref,record.num_het, record.num_hom_alt, record.num_unknown, \",\".join(hom_ref_samples), \",\".join(het_samples), \",\".join(hom_samples), \",\".join(mis_samples), breed, \"\".join(record.INFO['CSQ']), csq_impact, record.INFO['AF'][0], \",\".join(freq_list)]\n",
    "        print(\"\\t\".join(map(str,outlist)))\n",
    "    \n",
    "sample_dic=sample_dic()\n",
    "get_vcf_information(sample_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ff8e6",
   "metadata": {},
   "source": [
    "### Minor Allele Frequency and Density plot in R\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a51507e",
   "metadata": {},
   "outputs": [],
   "source": [
    " vcftools --gzvcf allsamples_FUT1.vcf.gz --freq --out MAF_fut1\n",
    "\n",
    "    # find minor allele frequency from all allele freq\n",
    "R2<- read.csv(\"MAF_FUT2.csv\")\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ploting maf\n",
    "a <- ggplot(R2, aes(maf)) + geom_density(fill = \"dodgerblue1\", colour = \"red\", alpha = 0.5, adjust = 80)\n",
    "a + theme_light()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940433da",
   "metadata": {},
   "source": [
    "### Haplotype Analysis\n",
    "\n",
    "#### Tool used : Beagle/5.2 , geneHapR Package (R), PopArt\n",
    "\n",
    "The first step in haplotype analysis is phasing of genotypes.  The VCF file has \"/\" symbol in GT format which means the genotype is Unphased.\n",
    "What does Phasing means?:\n",
    "So, we need to phase the genotype first and make it in \"|\" symbol.\n",
    "\n",
    "The current version I am using for the phasing of genotypes is Beagle/5.2. However, newer versions have been already available. Beagle  has error when there are missing genotypes in the samples which is stated as \"/.:\" and it cannot work with missing genotypes. So I needed to convert all the missing genotypes into 0/0 using sed command as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604c02e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: allsamples_Chr6.vcf: No such file or directory\r\n",
      "sed: no input files\r\n"
     ]
    }
   ],
   "source": [
    " cat allsamples_Chr6.vcf | sed -i 's/\\./0\\/0/g' > allsamples_Chr6.replaced.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d4fe6",
   "metadata": {},
   "source": [
    "This will change all . into 0/0 including . of ID even. haha. Next we will run a code to phase the genotypes of our 6th chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eda412",
   "metadata": {},
   "outputs": [],
   "source": [
    "java -jar /lustre/nobackup/WUR/ABGC/gyawa001/Beagle/beagle.28Jun21.220.jar\n",
    " gt=Sscrofa11.1_Chr6.replaced.vcf out=output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b4324",
   "metadata": {},
   "source": [
    "#### Counting number of haplotypes and constructing haplotype network for FUT genes\n",
    "Package \"geneHapR\" was used to make this analysis with some manual work in Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7955ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#“Introduction of ‘geneHapR’\n",
    "# Haplotype analysis\n",
    "\n",
    "library(adegenet)\n",
    "library(pegas)\n",
    "library(vcfR)\n",
    "\n",
    "#to read a vcf file\n",
    "vcf <- read.vcfR(\"allsamples_FUT1_phased_edited.vcf\")\n",
    "\n",
    "#to extract haplotypes\n",
    "haplotypes <- extract.haps(vcf)\n",
    "\n",
    "#to write haplotypes into csv file and save it in local computer\n",
    "write.csv(haplotypes, \"allsamples_FUTs.csv\", row.names = F)\n",
    "\n",
    "#the above steps are needed to do some editing in excel.\n",
    "#after that geneHapR can be used.\n",
    "\n",
    "\n",
    "#install package named \"geneHapR\"\n",
    "\n",
    "library(geneHapR)\n",
    "\n",
    "#import vcf file\n",
    "\n",
    "\n",
    "vcf <- import_vcf(\"allsamples_FUT1_phased_edited.vcf\")\n",
    "View(vcf)\n",
    "AccINFO <- import_AccINFO(\"AccINFO.txt\")\n",
    "View(AccINFO)\n",
    "#haplotype calculation\n",
    "\n",
    "hapResult <- vcf2hap(vcf, hapPrefix = \"H\" , hetero_remove = T, na_drop = T)\n",
    "hapResult\n",
    "View(hapResult)\n",
    "# Chech number of sites conclude in hapResult\n",
    "sites(hapResult)\n",
    "\n",
    "#Summary hapResult\n",
    "hapSummary <- hap_summary(hapResult)\n",
    "hapSummary\n",
    "View(hapSummary)\n",
    "write.csv(hapSummary, \"HapSummary_FUT1.csv\", row.names = T)\n",
    "\n",
    "hapSummary_removing_singletons <- hapSummary[1:44, ]\n",
    "#Visualize haplotye as table\n",
    "plotHapTable(hapSummary_removing_singletons)\n",
    "\n",
    "#hapnet calculation and Visualization\n",
    "hapNet <- get_hapNet(hapSummary_removing_singletons,\n",
    "                     AccINFO = AccINFO,\n",
    "                     groupName = \"Origin\")\n",
    "\n",
    "# plot haploNet\n",
    "\n",
    "plotHapNet(hapNet,\n",
    "           size = \"freq\",                   # circle size\n",
    "           scale = \"log2\",                 # scale circle with 'log10(size + 1)'\n",
    "           cex = 0.2,                       # size of hap symbol\n",
    "           col.link = 2,                    # link colors\n",
    "           link.width = 2,                  # link widths\n",
    "           show.mutation = 2,               # mutation types one of c(0,1,2,3)\n",
    "           legend = c(14.5, 6.5))        # legend position\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c5939",
   "metadata": {},
   "source": [
    "## Linkage Disequilibrium calculation\n",
    "\n",
    "To calculated LD between two markers was done. The first marker was the the significant marker from LIFT eQTL analysis of 4 tissues from 100 pigs samples. The signal was very high for lung tissue for FUT2 gene. To see if there is any relation between the significant SNP and the haplotype first linkage disequilibrium is carried out. We expect, the haplotype of FUT2 might have a some relation with expression signal from eQTL. There were 12 significant SNPs with same p,q values. We selected *6:53685920* as the SNP for eQTL and the LD between this SNP and the SNP marker in FUT2 haplotype was calculated.\n",
    "\n",
    "The important things to be consider are:\n",
    "1) First the VCF file must be changed into format recognised by PLINK. The generated file will be with .bim and .fam extension,\n",
    "\n",
    "2) Than, since our vcf file didn't have unique IDs, the IDs need to be given for each variants so later LD between SNPs based on variant ID can be calculated.\n",
    "\n",
    "3) LD calculation between variants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4806c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --vcf your_file.vcf --make-bed --out output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f02e7",
   "metadata": {},
   "source": [
    "There is no variant ID is the VCF file I am using. Thus I need to set the variant IDs for all the variants that are available in the output_file. The command below will allow to set the variants ID based on their location. This makes easier to calculate the LD between two SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ea1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "module load plink/2\n",
    "plink2 --bfile output_file --set-var-ids @:# --make-bed --out updated_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5319f532",
   "metadata": {},
   "source": [
    "The last step of calculating the LD between two SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272724f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --bfile allsamples_Chr6_updated --ld 6:53685920 6:54034275 --r2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433988af",
   "metadata": {},
   "source": [
    "The LD results consists of R-sq, D' and In phase alleles as shown below\n",
    "\n",
    "LD result:\n",
    "   R-sq = 0.635214       D' = 0.936853\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABG30306_Genomics/AandA",
   "language": "python",
   "name": "aanda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
